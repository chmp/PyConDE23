{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bc4d80-397f-4146-97ef-cea49907697c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from timing import setup\n",
    "\n",
    "setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac1f30f-2281-4c30-8b79-93b8fead635c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Optional, Union\n",
    "\n",
    "from cattrs.preconf.json import make_converter\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer, LAParams\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from decimal import Decimal\n",
    "from typing import Iterable, List, Tuple\n",
    "\n",
    "\n",
    "converter = make_converter()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Box:\n",
    "    x0: float\n",
    "    y0: float\n",
    "    x1: float\n",
    "    y1: float\n",
    "\n",
    "    def contains(self, xy: Tuple[float, float]) -> bool:\n",
    "        return self.x0 <= xy[0] < self.x1 and self.y0 <= xy[1] < self.y1\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Page:\n",
    "    number: int\n",
    "    words: \"List[Word]\"\n",
    "\n",
    "\n",
    "@dataclass(order=True)\n",
    "class Word:\n",
    "    x: float\n",
    "    y: float\n",
    "    text: str\n",
    "\n",
    "\n",
    "def pdf_extract(\n",
    "    path: Union[Path, str], *, pdf_extract_bin: Optional[Union[Path, str]] = None\n",
    ") -> Iterable[\"Page\"]:\n",
    "    if pdf_extract_bin is not None:\n",
    "        with subprocess.Popen(\n",
    "            [str(pdf_extract_bin), str(path)],\n",
    "            stdout=subprocess.PIPE,\n",
    "            encoding=\"utf8\",\n",
    "        ) as p:\n",
    "            for line in p.stdout:\n",
    "                yield converter.loads(line, Page)\n",
    "\n",
    "    else:\n",
    "        laparams = LAParams(\n",
    "            line_margin=0,\n",
    "            char_margin=0.1,\n",
    "            word_margin=0.1,\n",
    "        )\n",
    "        for page_idx, page_layout in enumerate(extract_pages(path, laparams=laparams)):\n",
    "            yield Page(\n",
    "                number=page_idx + 1,\n",
    "                words=sorted(\n",
    "                    Word(\n",
    "                        x=element.bbox[0],\n",
    "                        y=element.bbox[1],\n",
    "                        text=element.get_text().rstrip(),\n",
    "                    )\n",
    "                    for element in page_layout\n",
    "                    if isinstance(element, LTTextContainer)\n",
    "                ),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab7f76-8ad8-431c-bfaf-55cfffdcf398",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"data/pdf_files.json\", \"rt\") as fobj:\n",
    "    pdf_files = json.load(fobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ccfbe7-6b3d-4558-9a5e-ec7059a38b15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subprocess.run([\"cargo\", \"build\", \"-p\", \"pdf-parser\", \"--release\"], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ce15ad-e314-4f3d-8586-7ac482767c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%record-time parse-pdf-python\n",
    "pages = list(pdf_extract(pdf_files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f2538-187c-428e-8333-04efc058c517",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%record-time parse-pdf-rust\n",
    "pages = list(pdf_extract(pdf_files[0], pdf_extract_bin=\"./target/release/pdf-parser.exe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732fc9d3-8975-4635-af2e-d1ad5c33020d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import re\n",
    "\n",
    "Structure = List[Tuple[int, Word]]\n",
    "\n",
    "account_block_start = [\"Girokonto\", \"Buchungstag\", \"Valuta\", \"Alter\"]\n",
    "account_page_start = [\"Buchungstag\", \"Valuta\"]\n",
    "account_block_end = [\"Neuer\"]\n",
    "\n",
    "structure_box = Box(55, 55, 65, 720)\n",
    "\n",
    "date_re = re.compile(r\"(?P<ahead>A?)(?P<day>\\d{2})\\.(?P<month>\\d{2})\\.(?P<year>\\d{4})\")\n",
    "\n",
    "\n",
    "def parse_bank_statement(\n",
    "    path, pdf_extract_bin=None\n",
    ") -> List[Tuple[datetime.date, Decimal]]:\n",
    "    pages = list(pdf_extract(path, pdf_extract_bin=pdf_extract_bin))\n",
    "\n",
    "    structure = [\n",
    "        (page_idx, word)\n",
    "        for page_idx, page in enumerate(pages)\n",
    "        for word in filter_structure_elements(page.words)\n",
    "    ]\n",
    "\n",
    "    structure = find_account_start(structure)\n",
    "    item_starts = find_item_starts(structure)\n",
    "\n",
    "    res = []\n",
    "    for page_idx, height, is_pos in item_starts:\n",
    "        if not is_pos:\n",
    "            continue\n",
    "\n",
    "        items_in_line = sorted(\n",
    "            filter_words_at_height(pages[page_idx].words, height),\n",
    "            key=lambda word: word.x,\n",
    "        )\n",
    "        res.append(parse_line(items_in_line))\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def find_account_start(structure: Structure) -> Structure:\n",
    "    for i in range(len(structure)):\n",
    "        if get_text(structure[i : i + 4]) == account_block_start:\n",
    "            return structure[i + 4 :]\n",
    "\n",
    "    raise ValueError(\"Could not find account start\")\n",
    "\n",
    "\n",
    "def find_item_starts(structure: Structure) -> List[Tuple[int, float, bool]]:\n",
    "    item_starts = []\n",
    "\n",
    "    for i in range(0, len(structure), 2):\n",
    "        if get_text(structure[i : i + 1]) == account_block_end:\n",
    "            page_idx, word = structure[i]\n",
    "            item_starts.append((page_idx, word.y, False))\n",
    "            break\n",
    "\n",
    "        if get_text(structure[i : i + 2]) == account_page_start:\n",
    "            continue\n",
    "\n",
    "        page_idx, word = structure[i]\n",
    "        item_starts.append((page_idx, word.y, True))\n",
    "\n",
    "    return item_starts\n",
    "\n",
    "\n",
    "def parse_line(items_in_line) -> Tuple[datetime.date, Decimal]:\n",
    "    m = date_re.match(items_in_line[0].text)\n",
    "    assert m is not None\n",
    "    assert m.group(\"ahead\") == \"\"\n",
    "\n",
    "    date = datetime.date(\n",
    "        int(m.group(\"year\")),\n",
    "        int(m.group(\"month\")),\n",
    "        int(m.group(\"day\")),\n",
    "    )\n",
    "    delta = parse_number(items_in_line[-1].text)\n",
    "\n",
    "    return date, delta\n",
    "\n",
    "\n",
    "def get_text(structure: Structure) -> List[str]:\n",
    "    return [word.text for _, word in structure]\n",
    "\n",
    "\n",
    "def parse_number(val: str) -> Decimal:\n",
    "    return Decimal(val.replace(\".\", \"\").replace(\",\", \".\"))\n",
    "\n",
    "\n",
    "def filter_structure_elements(elems: Iterable[Word]) -> List[Word]:\n",
    "    elems = (word for word in elems if word.text.strip())\n",
    "    elems = filter_words_in_box(elems, structure_box)\n",
    "    elems = sorted(elems, key=lambda word: word.y, reverse=True)\n",
    "    return elems\n",
    "\n",
    "\n",
    "def filter_words_in_box(words: Iterable[Word], box: Box) -> Iterable[Word]:\n",
    "    return (word for word in words if box.contains((word.x, word.y)))\n",
    "\n",
    "\n",
    "def filter_words_at_height(\n",
    "    words: Iterable[Word], y: float, delta: float = 5.0\n",
    ") -> Iterable[Word]:\n",
    "    return (word for word in words if abs(word.y - y) < delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba1a5b3-dc8d-4c5e-8ea8-9e24a7900a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for page in pages:\n",
    "    structure_elements = filter_structure_elements(page.words)\n",
    "    structure_text = [word.text for word in structure_elements]\n",
    "\n",
    "    account_start = None\n",
    "\n",
    "    for i in range(len(structure_elements)):\n",
    "        if structure_text[i : i + 4] == [\"Girokonto\", \"Buchungstag\", \"Valuta\", \"Alter\"]:\n",
    "            account_start = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37259bfe-3fa4-425a-88a2-2997beb3063d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%record-time convert-pdf-end-to-end-python\n",
    "\n",
    "for path in pdf_files:\n",
    "    parse_bank_statement(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1577dfcb-65e1-496a-bdd8-7ba140ed3127",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%record-time convert-pdf-end-to-end-rust\n",
    "\n",
    "for path in pdf_files:\n",
    "    parse_bank_statement(path, pdf_extract_bin=\"./target/release/pdf-parser.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9bcc61-c0d8-45b3-9f0b-932d6d424336",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
